[
  {
    "objectID": "Hands-on_Ex3/Data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex3/Data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html",
    "title": "Hands-on_Ex2",
    "section": "",
    "text": "Lets make make sure that spdep, sf, tmap and tidyverse packages of R are currently installed \n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#getting-started",
    "title": "Hands-on_Ex2",
    "section": "",
    "text": "Lets make make sure that spdep, sf, tmap and tidyverse packages of R are currently installed \n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#importing-geosptial-data-into-r",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#importing-geosptial-data-into-r",
    "title": "Hands-on_Ex2",
    "section": "Importing Geosptial Data into R",
    "text": "Importing Geosptial Data into R\n\nImporting shapefile into R env\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImporting CSV file into into R env\n\nhunan2012 &lt;- read.csv(\"data/aspatial/Hunan_2012.csv\")\n\n\n\nPerforming relational join\nUsing left_join() of dplyr package to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#visualising-regional-development-indicator",
    "title": "Hands-on_Ex2",
    "section": "Visualising Regional Development Indicator",
    "text": "Visualising Regional Development Indicator\n\nPreparing a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) + tm_polygons() + tm_text(\"NAME_3\",size = 0.5)\ngdppc &lt;- qtm(hunan,\"GDPPC\")\ntmap_arrange(basemap,gdppc,asp=1,ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#computing-contiguity-spatial-weights",
    "title": "Hands-on_Ex2",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nIn spatial analysis - a neighborhood refers to those data points that we consider to be proximate to a given focal data point. With area-based vector data (polygons), there are multiple ways to measure proximity:\n\nContiguity-based neighbors consider neighboring polygons to be those that “touch” a focal polygon, and are derived in spdep package with the poly2nb() function\nDistance-based neighbors are those within a given proximity threshold to a focal polygon; distances are measured between polygon centroid using the knn2nb() function\n\nContiguity happens when two spatial units share a common border.\nQueen Contiguity: A neigboring polygon is one that shares a vertex with the focal polygon Rook Contiguity: A neigboring polygon is one that shares an edge (line segment) with the focal polygon\n\nComputing (QUEEN) contiguity based neighbours\npoly2nb() of spdep package to compute contiguity weight matrices for the study area.\n\npacman::p_load(spdep)\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report shows that:\nThere are 88 area units in Hunan The most connected area unit has 11 neighbors (links) The two least connected areas have only 1 neighbor\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$NAME_3[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of the five neighboring polygons:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nTo retrieve the GDPPC of these five countries:\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\n\n\nCreating (ROOK) contiguity based neighbours\nTo compute Rook contiguity weight matrix:\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report shows that:\nThere are 88 area units in Hunan The most connected area unit has 10 neighbors (links) The two least connected areas have only 1 neighbor\n\n\nVisualising contiguity weight\nA connectivity graph takes a point and displays a line connecting to each neighboring point. The current geospatial dataset only has polygons at the moment, so we will need to compute points in order to make our connectivity graphs. The most typical method for this will be using polygon centroids.\n\npacman::p_load(purrr)\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\nPlotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"yellow\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#computing-distance-based-neighbours",
    "title": "Hands-on_Ex2",
    "section": "Computing distance based neighbours",
    "text": "Computing distance based neighbours\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\nComputing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nuse str() to display the content of wm_d62 weight matrix\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nPlotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\nComputing adaptive distance weight matrix\nIn fixed distance weight matrices, more densely populated areas (usually the urban areas) tend to have more neighbors and the less densely settled areas (usually the rural counties) tend to have fewer neighbors. Having many neighbors smoothes the neighbor relationship across more neighbors.\nIt is possible to control the numbers of neighbors directly using k-nearest neighbors, either accepting asymmetric neighbors or imposing symmetry – stating k = n as a parameter where n = number of neighbors:\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\n\nPlotting distance based neighbours\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#computing-inversed-distance-weights-idw",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#computing-inversed-distance-weights-idw",
    "title": "Hands-on_Ex2",
    "section": "Computing Inversed Distance Weights (IDW)",
    "text": "Computing Inversed Distance Weights (IDW)\nDerive a spatial weight matrix based on the Inversed Distance method.\n\n1.) Compute the distances between areas by using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n2.) Assign weights to each neighboring polygon\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex2/Hands-on_Ex2.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex2/Hands-on_Ex2.html#application-of-spatial-weight-matrix",
    "title": "Hands-on_Ex2",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\nSpatial lag variables are used to account for spatial autocorrelation in the data, where the values of a variables in one location are influenced by the values of the variable in nearby locations. A spatially lagged variable is a weighted sum or a weighted average of the neighboring values for that variable where Lag = E(x) or average value of the neighborhood\n\nSpatial lag with row-standardized weights\nThis is the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values. #### 1.) Creating spatial lagged values\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\n2.) Appending spatial lagged values to main dataframe\n\nlag_list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag_res &lt;- as.data.frame(lag_list)\ncolnames(lag_res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag_res)\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\n\n3.) Comparing both the GDPPC and spatial lag GDPPC\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nSpatial lag as a sum of neighboring values\nAn alternative to calculating spatial lag is by adding up the neighboring values from assigning binary weights.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nComparing both the GDPPC and Spatial Lag Sum GDPPC\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\nSpatial Window Avg\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights. #### 1.) Using include.self() To add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that now [1] has six neighbours instead of five.\n\n2.) nb2listw() to obtain weights\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\n\n3.) creating lag variable\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\n\n\n4.) Convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\n\n\n5.) Comparing lag GDPPC to window average lag GDPPC\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\nSpatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\n\n1.) Using include.self()\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\n\n\n2.) nb2listw() to obtain weights\nNow we obtain weights with nb2listw()\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\n\n\n3.) Compute lag variable\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\n\nConverting lag variable to dataframe\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\n\n\nComparing all plots\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, lag_sum_gdppc, w_avg_gdppc, w_sum_gdppc, \n             nrow = 2, asp = 1)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 3/data/geospatial/MPSZ-2019.html",
    "href": "In-class Exercise/In-class Exercise 3/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html",
    "title": "In-class Exercise 2:",
    "section": "",
    "text": "pacman::p_load(tmap,sf,sfdep,tidyverse,knitr, plotly,zoo,kendall)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#getting-started",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#getting-started",
    "title": "In-class Exercise 2:",
    "section": "",
    "text": "pacman::p_load(tmap,sf,sfdep,tidyverse,knitr, plotly,zoo,kendall)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#the-data",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#the-data",
    "title": "In-class Exercise 2:",
    "section": "The Data",
    "text": "The Data\n\nImporting the data\n\nHunan, a geospatial data set in ESRI shapefile format\nHunan_2012, an attribute data set in csv format\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/Users/youting/ytquek/ISSS624/In-class Exercise/In-class Exercise 2/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nCombine both data frames\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#computing-contiguity-spatial-weights",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#computing-contiguity-spatial-weights",
    "title": "In-class Exercise 2:",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nUse poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. Note: A “queen” argument taking TRUE/FALSE option can be passed. Default is set to TRUE.\n\nComputing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#global-spatial-autocorrelation",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#global-spatial-autocorrelation",
    "title": "In-class Exercise 2:",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\nCompute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\nComputing local Moran’s I\nLocal Moran’s I of GDPPC at country level\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(local_moran)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#time-series-cube",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#time-series-cube",
    "title": "In-class Exercise 2:",
    "section": "Time Series Cube",
    "text": "Time Series Cube\n\nGDPPC &lt;- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan, \n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\nis_spacetime_cube(GDPPC)\n\n[1] FALSE\n\n\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb,geometry,\n                                  scale = 1,\n                                  alpha=1),\n         .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#computing-gi",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#computing-gi",
    "title": "In-class Exercise 2:",
    "section": "Computing Gi*",
    "text": "Computing Gi*\n\ngi_stars &lt;- GDPPC_nb %&gt;%\n  group_by(Year) %&gt;%\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) %&gt;%\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#emerging-hot-spots",
    "href": "In-class Exercise/In-class Exercise 2/inclass_ex2.html#emerging-hot-spots",
    "title": "In-class Exercise 2:",
    "section": "Emerging Hot Spots",
    "text": "Emerging Hot Spots\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim = 99\n)\n\nhunan_ehsa &lt;- hunan %&gt;%\n  left_join(ehsa,\n            by = join_by(County==location))\n\n\nVisualising the distribution of EHSA classes\n\nehsa_sig &lt;- hunan_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\n\ntmap_mode(\"plot\")\ntm_shape(hunan_ehsa) +\n  tm_polygons +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html",
    "href": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html",
    "title": "In class Exercise 1: First Geospatial DA",
    "section": "",
    "text": "The code chunk below loadfs the following packages:\n\ntmap for thematic mapping\nsf for geospatial data handling\ntidyverse for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#getting-started",
    "href": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#getting-started",
    "title": "In class Exercise 1: First Geospatial DA",
    "section": "",
    "text": "The code chunk below loadfs the following packages:\n\ntmap for thematic mapping\nsf for geospatial data handling\ntidyverse for non-spatial data handling\n\n\npacman::p_load(tmap, sf, tidyverse)"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#importing-the-od-data",
    "href": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#importing-the-od-data",
    "title": "In class Exercise 1: First Geospatial DA",
    "section": "Importing the OD Data",
    "text": "Importing the OD Data\nFirstly we will import the Passenger volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\n\norigtrip_7_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 7 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\", layer =\"BusStop\") %&gt;% st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/youting/ytquek/ISSS624/In-class Exercise/In-class Exercise 1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer =  \"MPSZ-2019\") %&gt;% st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS624/In-class Exercise/In-class Exercise 1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#extracting-the-data-for-analysis",
    "href": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#extracting-the-data-for-analysis",
    "title": "In class Exercise 1: First Geospatial DA",
    "section": "Extracting the data for Analysis",
    "text": "Extracting the data for Analysis\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…\n\n\n\nImporting polyline feature data in shapefile form\n\ncyclingpath = st_read(dsn = \"data/geospatial\", \n                         layer = \"CyclingPathGazette\") \n\nReading layer `CyclingPathGazette' from data source \n  `/Users/youting/ytquek/ISSS624/In-class Exercise/In-class Exercise 1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\nImporting GIS data in kml format\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\") \n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/youting/ytquek/ISSS624/In-class Exercise/In-class Exercise 1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message above reveals that preschool is a point feature data frame. There are a total of 2290 features and 2 fields. Different from the previous two simple feature data frame, preschool is in wgs84 coordinates system."
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "In-class Exercise/In-class Exercise 1/In-class Exercise 1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "In class Exercise 1: First Geospatial DA",
    "section": "Checking the Content of A Simple Feature Data Frame",
    "text": "Checking the Content of A Simple Feature Data Frame\n\nst_geometry(mpsz)\n\nGeometry set for 332 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html",
    "href": "Project/TakeHome_Ex1.html",
    "title": "Take-home-project",
    "section": "",
    "text": "Lets make make sure that sfdep, sf, tmap and tidyverse packages of R are currently installed \n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr, plotly, zoo, Kendall, mapview, spdep)\n\n\n\nFirstly we will import the Passenger volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\n\n\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\nWe will filter out the data according to the requirements set out by Professor 1.) “Weekday @ 6-9am”\n\norigtrip_6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_6_9))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1973\n\n\n01013\n952\n\n\n01019\n1789\n\n\n01029\n2561\n\n\n01039\n2938\n\n\n01059\n1651\n\n\n\n\nwrite_rds(origtrip_6_9, \"data/rds/origtrip_6_9.rds\")\n\n2.) “Weekday @ 5-8pm”\n\norigtrip_17_20 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\nglimpse(origtrip_17_20)\n\nRows: 5,035\nColumns: 2\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ TRIPS          &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n\n\n\nkable(head(origtrip_17_20))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n8448\n\n\n01013\n7328\n\n\n01019\n3608\n\n\n01029\n9317\n\n\n01039\n12937\n\n\n01059\n2133\n\n\n\n\nwrite_rds(origtrip_17_20, \"data/rds/origtrip_17_20.rds\")\n\n3.) “Weekend @ 11am-2pm”\n\norigtrip_11_14 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_11_14))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n2273\n\n\n01013\n1697\n\n\n01019\n1511\n\n\n01029\n3272\n\n\n01039\n5424\n\n\n01059\n1062\n\n\n\n\nwrite_rds(origtrip_11_14, \"data/rds/origtrip_11_14.rds\")\n\n4.) “Weekend @ 4-7pm”\n\norigtrip_16_19 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_16_19))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n3208\n\n\n01013\n2796\n\n\n01019\n1623\n\n\n01029\n4244\n\n\n01039\n7403\n\n\n01059\n1190\n\n\n\n\nwrite_rds(origtrip_16_19, \"data/rds/origtrip_16_19.rds\")\n\n\norigtrip_11_14 &lt;- read_rds(\"data/rds/origtrip_11_14.rds\")\norigtrip_16_19 &lt;- read_rds(\"data/rds/origtrip_16_19.rds\")\norigtrip_17_20 &lt;- read_rds(\"data/rds/origtrip_17_20.rds\")\norigtrip_6_9 &lt;- read_rds(\"data/rds/origtrip_6_9.rds\")\n\n\n\n\n\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#getting-started",
    "href": "Project/TakeHome_Ex1.html#getting-started",
    "title": "Take-home-project",
    "section": "",
    "text": "Lets make make sure that sfdep, sf, tmap and tidyverse packages of R are currently installed \n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr, plotly, zoo, Kendall, mapview, spdep)\n\n\n\nFirstly we will import the Passenger volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\n\n\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\nWe will filter out the data according to the requirements set out by Professor 1.) “Weekday @ 6-9am”\n\norigtrip_6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_6_9))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1973\n\n\n01013\n952\n\n\n01019\n1789\n\n\n01029\n2561\n\n\n01039\n2938\n\n\n01059\n1651\n\n\n\n\nwrite_rds(origtrip_6_9, \"data/rds/origtrip_6_9.rds\")\n\n2.) “Weekday @ 5-8pm”\n\norigtrip_17_20 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\nglimpse(origtrip_17_20)\n\nRows: 5,035\nColumns: 2\n$ ORIGIN_PT_CODE &lt;fct&gt; 01012, 01013, 01019, 01029, 01039, 01059, 01109, 01112,…\n$ TRIPS          &lt;dbl&gt; 8448, 7328, 3608, 9317, 12937, 2133, 322, 45010, 27233,…\n\n\n\nkable(head(origtrip_17_20))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n8448\n\n\n01013\n7328\n\n\n01019\n3608\n\n\n01029\n9317\n\n\n01039\n12937\n\n\n01059\n2133\n\n\n\n\nwrite_rds(origtrip_17_20, \"data/rds/origtrip_17_20.rds\")\n\n3.) “Weekend @ 11am-2pm”\n\norigtrip_11_14 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_11_14))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n2273\n\n\n01013\n1697\n\n\n01019\n1511\n\n\n01029\n3272\n\n\n01039\n5424\n\n\n01059\n1062\n\n\n\n\nwrite_rds(origtrip_11_14, \"data/rds/origtrip_11_14.rds\")\n\n4.) “Weekend @ 4-7pm”\n\norigtrip_16_19 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nkable(head(origtrip_16_19))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n3208\n\n\n01013\n2796\n\n\n01019\n1623\n\n\n01029\n4244\n\n\n01039\n7403\n\n\n01059\n1190\n\n\n\n\nwrite_rds(origtrip_16_19, \"data/rds/origtrip_16_19.rds\")\n\n\norigtrip_11_14 &lt;- read_rds(\"data/rds/origtrip_11_14.rds\")\norigtrip_16_19 &lt;- read_rds(\"data/rds/origtrip_16_19.rds\")\norigtrip_17_20 &lt;- read_rds(\"data/rds/origtrip_17_20.rds\")\norigtrip_6_9 &lt;- read_rds(\"data/rds/origtrip_6_9.rds\")\n\n\n\n\n\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\n\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\n\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#geospatial-data-wrangling",
    "href": "Project/TakeHome_Ex1.html#geospatial-data-wrangling",
    "title": "Take-home-project",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nCombining Busstop and mpsz\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\nglimpse(busstop_mpsz)\n\nRows: 5,156\nColumns: 2\n$ BUS_STOP_N &lt;chr&gt; \"13099\", \"13089\", \"06151\", \"13211\", \"13139\", \"13109\", \"1311…\n$ SUBZONE_C  &lt;chr&gt; \"RVSZ05\", \"RVSZ05\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\", \"SRSZ01\",…\n\n\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.csv\")  \n\n\norigin_6_9 &lt;- left_join(origtrip_6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\nglimpse(origin_6_9)\n\nRows: 312\nColumns: 2\n$ ORIGIN_SZ &lt;chr&gt; \"AMSZ01\", \"AMSZ02\", \"AMSZ03\", \"AMSZ04\", \"AMSZ05\", \"AMSZ06\", …\n$ TOT_TRIPS &lt;dbl&gt; 116600, 226521, 199437, 114549, 70770, 102390, 23231, 28011,…\n\n\n\norigin_17_20 &lt;- left_join(origtrip_17_20 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\n\norigin_11_14 &lt;- left_join(origtrip_11_14 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))\n\n\norigin_16_19 &lt;- left_join(origtrip_16_19 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C) %&gt;%\n  group_by(ORIGIN_SZ) %&gt;%\n  summarise(TOT_TRIPS = sum(TRIPS))"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#setting-up-the-hexagon-grid",
    "href": "Project/TakeHome_Ex1.html#setting-up-the-hexagon-grid",
    "title": "Take-home-project",
    "section": "Setting up the Hexagon Grid",
    "text": "Setting up the Hexagon Grid\n\nDrawing the Hexagon Grid\nDrawing the hexagon grid over the mpsz map\n\narea_honeycomb_grid = st_make_grid(mpsz, c(500), what = \"polygons\", square = FALSE)\n\n\n\nTo sf and add grid ID\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\n\nbusstop_honeycomb &lt;- st_intersection(honeycomb_grid_sf,busstop) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry()\n\n\nwrite_rds(busstop_honeycomb, \"data/rds/busstop_honeycomb.csv\")\n\n\nduplicate &lt;- busstop_honeycomb %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nbusstop_honeycomb &lt;- unique(busstop_honeycomb)\n\n\n\nremove grid without value of 0 (i.e. no points in side that grid)\n\nbusstop_honeycomb &lt;- busstop_honeycomb %&gt;%\n  filter(!is.na(grid_id) & grid_id &gt; 0)"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#assign-every-bus-stop-with-a-grid-id",
    "href": "Project/TakeHome_Ex1.html#assign-every-bus-stop-with-a-grid-id",
    "title": "Take-home-project",
    "section": "Assign every Bus Stop with a Grid ID",
    "text": "Assign every Bus Stop with a Grid ID\n\norigin_6_9 &lt;- left_join(busstop_honeycomb, origtrip_6_9,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\norigin_6_9 &lt;- origin_6_9 %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\norigin_17_20 &lt;- left_join(busstop_honeycomb, origtrip_17_20,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\norigin_17_20 &lt;- origin_17_20 %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\norigin_11_14 &lt;- left_join(busstop_honeycomb, origtrip_11_14,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\norigin_11_14 &lt;- origin_11_14 %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\norigin_16_19 &lt;- left_join(busstop_honeycomb, origtrip_16_19,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\norigin_16_19 &lt;- origin_16_19 %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#weekday-morning-peak-6am-9am",
    "href": "Project/TakeHome_Ex1.html#weekday-morning-peak-6am-9am",
    "title": "Take-home-project",
    "section": "Weekday Morning Peak 6am-9am",
    "text": "Weekday Morning Peak 6am-9am\n\ntotal_trips_by_grid_6_9 &lt;- origin_6_9 %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid_6_9 &lt;- total_trips_by_grid_6_9 %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf_6_9 &lt;- st_sf(total_trips_by_grid_6_9)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf_6_9) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#weekday-afternoon-peak-5pm---8pm",
    "href": "Project/TakeHome_Ex1.html#weekday-afternoon-peak-5pm---8pm",
    "title": "Take-home-project",
    "section": "Weekday Afternoon Peak 5pm - 8pm",
    "text": "Weekday Afternoon Peak 5pm - 8pm\n\ntotal_trips_by_grid_17_20 &lt;- origin_17_20 %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid_17_20 &lt;- total_trips_by_grid_17_20 %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf_17_20 &lt;- st_sf(total_trips_by_grid_17_20)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb1 = tm_shape(total_trips_by_grid_sf_17_20) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Afternoon Peak 5 - 8 pm\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\n\nmap_honeycomb1"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#weekdayweekend-morning-peak-11am-2pm",
    "href": "Project/TakeHome_Ex1.html#weekdayweekend-morning-peak-11am-2pm",
    "title": "Take-home-project",
    "section": "Weekday/Weekend Morning Peak 11am-2pm",
    "text": "Weekday/Weekend Morning Peak 11am-2pm\n\ntotal_trips_by_grid &lt;- origin_11_14 %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#weekendholiday-peak-4pm-7pm",
    "href": "Project/TakeHome_Ex1.html#weekendholiday-peak-4pm-7pm",
    "title": "Take-home-project",
    "section": "Weekend/Holiday Peak 4pm-7pm",
    "text": "Weekend/Holiday Peak 4pm-7pm\n\ntotal_trips_by_grid &lt;- origin_16_19 %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb"
  },
  {
    "objectID": "Project/TakeHome_Ex1.html#local-indicators-of-spatial-association-lisa-analysis",
    "href": "Project/TakeHome_Ex1.html#local-indicators-of-spatial-association-lisa-analysis",
    "title": "Take-home-project",
    "section": "Local Indicators of Spatial Association (LISA) Analysis",
    "text": "Local Indicators of Spatial Association (LISA) Analysis\n\nComputing Contiguity Spatial Weights\na z-score, a pseudo p-value, and a code representing the cluster type for each statistically significant feature. The z-scores and pseudo p-values represent the statistical significance of the computed index values.\n\nStep 1 Check for null Neighbours\n\n# Check for empty neighbor sets\nempty_neighbors &lt;- which(sapply(total_trips_by_grid_sf, length) == 0)\n\n# Print the indices of observations with no neighbors\nif (length(empty_neighbors) &gt; 0) {\n  cat(\"Observations with no neighbors:\", empty_neighbors, \"\\n\")\n} else {\n  cat(\"All observations have at least one neighbor.\\n\")\n}\n\nAll observations have at least one neighbor.\n\n\n\n\nStep 2 Create a list of all neighbours\n\n# Create neighbor list\nwm08 &lt;- total_trips_by_grid_sf %&gt;%\n  mutate(nb = st_contiguity(area_honeycomb_grid))\n\n# Filter out observations where 'nb' contains the value 0\n# Assuming '0' is an unwanted value in the 'nb' list\nwm08 &lt;- wm08 %&gt;%\n  filter(!sapply(nb, function(x) any(x == 0)))\n\n# Now, you can proceed with creating the weights\nwm08 &lt;- wm08 %&gt;%\n  mutate(\n    wt = st_weights(nb, style = \"W\"),\n    .before = 1\n  )\n\n\n\nStep 3 Plot a map based on the list of neighbours\n\n# Set map to static\ntmap_mode(\"view\")\n\nmap_08 &lt;- tm_shape(wm08) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"PuRd\",\n    style = \"pretty\",\n    title = \"Trip sizes\"\n  ) +\n  tm_layout(main.title = \"Total Bus Trips Across the Island \",\n            main.title.size = 1,\n            main.title.position = \"center\",\n            legend.position = c(\"left\", \"top\"),\n            legend.height = .6,\n            legend.width = .2,\n            frame = FALSE\n            \n  )\n\nmap_08\n\n\n\n\n\n\n\n# Step 1: Merge the data\n# Ensure that both wm08 and Origin_6_9 have 'grid_id' as a common key\n# and that it's of the same data type in both data frames\nmerged_data &lt;- wm08 %&gt;% \n  left_join(origin_6_9, by = \"grid_id\")\n\n# Step 2: Prepare the data\n# Assuming 'area_honeycomb_grid' is the geometry column in wm08\n# Convert to an sf object if not already\nif (!(\"sf\" %in% class(merged_data))) {\n  merged_data &lt;- st_as_sf(merged_data, geom_col = \"area_honeycomb_grid\")\n}\n\n# Recreate the neighbor list and spatial weights\n# Ensure 'nb' is in the correct format (e.g., created using st_contiguity or similar)\nlistw &lt;- nb2listw(merged_data$nb, style = \"W\")\n\nmerged_data$standardized_trips &lt;- as.numeric(scale(merged_data$TRIPS, center = TRUE, scale = TRUE))\n\n# Remove NA values from the data\nmerged_data &lt;- merged_data[!is.na(merged_data$standardized_trips), ]\n\n# Recreate the spatial weights to match the filtered data\nlistw &lt;- nb2listw(merged_data$nb, style = \"W\")\n\n# Check if the lengths match\nif (nrow(merged_data) != length(listw$neighbours)) {\n  stop(\"The length of the data and the spatial weights list do not match.\")\n}\n\n# Run the Monte Carlo test for Local Moran's \nlisa &lt;- merged_data %&gt;%\n  mutate(local_moran = local_moran(\n    total_trips, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(local_moran)\n\n# unnest the dataframe column\ntidyr::unnest(lisa)\n\nSimple feature collection with 23878 features and 19 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 4167.538 ymin: 27151.39 xmax: 46917.54 ymax: 50245.4\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 23,878 × 20\n      ii      eii var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 0.285  0.00370 0.0969 0.903 0.367     0.02         0.01    -3.61    17.7 \n 2 0.285  0.00370 0.0969 0.903 0.367     0.02         0.01    -3.61    17.7 \n 3 0.285  0.00370 0.0969 0.903 0.367     0.02         0.01    -3.61    17.7 \n 4 0.284  0.0589  0.0614 0.908 0.364     0.04         0.02    -2.16     5.87\n 5 0.284 -0.0200  0.284  0.570 0.568     0.02         0.01    -4.33    21.5 \n 6 0.270  0.0193  0.0489 1.13  0.257     0.04         0.02    -2.39     8.27\n 7 0.270  0.0193  0.0489 1.13  0.257     0.04         0.02    -2.39     8.27\n 8 0.270  0.0193  0.0489 1.13  0.257     0.04         0.02    -2.39     8.27\n 9 0.278 -0.00361 0.0873 0.953 0.341     0.02         0.01    -2.73     8.47\n10 0.278 -0.00361 0.0873 0.953 0.341     0.02         0.01    -2.73     8.47\n# ℹ 23,868 more rows\n# ℹ 11 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, wt &lt;dbl&gt;,\n#   grid_id &lt;int&gt;, total_trips &lt;dbl&gt;, area_honeycomb_grid &lt;POLYGON [m]&gt;,\n#   nb &lt;int&gt;, BUS_STOP_N &lt;chr&gt;, TRIPS &lt;dbl&gt;, standardized_trips &lt;dbl&gt;\n\n# Extracting p-values or other results from local_moran_mc\n# ...\n\n\n# Set map to static\ntmap_mode(\"view\")\n\nmap_m1 &lt;- tm_shape(merged_data) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"PuRd\",\n    style = \"pretty\",\n    title = \"Trip sizes\"\n  ) +\n  tm_layout(main.title = \"Total Bus Trips Across the Island \",\n            main.title.size = 1,\n            main.title.position = \"center\",\n            legend.position = c(\"left\", \"top\"),\n            legend.height = .6,\n            legend.width = .2,\n            frame = FALSE\n  )\n\nmap_m1"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html",
    "href": "Hands-on_Ex1/Hands-onEx1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, i learn how to import and wrangle geospatial data in using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#overview",
    "href": "Hands-on_Ex1/Hands-onEx1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, i learn how to import and wrangle geospatial data in using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#getting-started",
    "href": "Hands-on_Ex1/Hands-onEx1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below install and load sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#importing-geospatial-data",
    "href": "Hands-on_Ex1/Hands-onEx1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nImporting Polygon feature data in shapefile format\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\nImporting polyline feature data in shapefile form\nThe code chunk below uses st_read() function of sf package to import CyclingPath shapefile into R as line feature data frame.\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex1/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\n\n\nImporting GIS data in KML format\nThe PreSchoolsLocation is in kml format. The code chunk below will be used to import the kml into R. Notice that in the code chunk below, the complete path and the kml file extension were provided.\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex1/data/geospatial/PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex1/Hands-onEx1.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Checking the Content of A Simple Feature Data Frame",
    "text": "Checking the Content of A Simple Feature Data Frame\n\nWorking with st_geometry\nWe can retrieve the geometry list-column in this case by mpsz$geom or mpsz, but the more general way uses st_geometry() as shown in the code chunk below.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\nWorking with Glimpse\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nWorking with head()\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex1/Hands-onEx1.html#plotting-the-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting the Geospatial Data",
    "text": "Plotting the Geospatial Data\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum as shown above. We can, however, choose to plot only the geometry by using the code chunk below.\n\nplot(st_geometry(mpsz))\n\n\n\n\nAlternatively, we can also choose the plot the sf object by using a specific attribute as shown in the code chunk below.\n\nplot(mpsz[\"SUBZONE_C\"])"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#projection-transformation",
    "href": "Hands-on_Ex1/Hands-onEx1.html#projection-transformation",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Projection Transformation",
    "text": "Projection Transformation\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nIn this section, you will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\nAssigning EPSG code to a simple feature data frame\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nTo check, we use:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#transforming-the-original-data-from-geographic-coordinate-system-to-projected-coordinate-system",
    "href": "Hands-on_Ex1/Hands-onEx1.html#transforming-the-original-data-from-geographic-coordinate-system-to-projected-coordinate-system",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Transforming the original data from geographic coordinate system to projected coordinate system",
    "text": "Transforming the original data from geographic coordinate system to projected coordinate system\nTransforming the projection of preschool from wgs84 to svy21 Let us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool,  crs = 3414)\n\nTo check, we use:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#importing-aspatial-data",
    "href": "Hands-on_Ex1/Hands-onEx1.html#importing-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Aspatial Data",
    "text": "Importing Aspatial Data\nImport Data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\") \n\nRows: 3483 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe code chunk below shows list() of Base R instead of glimpse() is used to do the job.\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,483 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Villa in…  367042 Belinda   East Region         Tampines          1.35\n 2  71896 Home in …  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Home in …  367042 Belinda   East Region         Tampines          1.35\n 4 275343 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Home in …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 Rental u… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Rental u… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 369141 Place to… 1521514 Elizabeth Central Region      Newton            1.31\n# ℹ 3,473 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\nCreating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates. crs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io. %&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system. Let us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Villa in Singapore · ★4.44 · 2 bedroom…\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; 150, 80, 80, 55, 69, 220, 85, 75, 45, 7…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 92, 60, 60, 92,…\n$ number_of_reviews              &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 133, 18, 6, 81,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0.12, 0.09, 0.9…\n$ calculated_host_listings_count &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52, 52, 7, 7, 1,…\n$ availability_365               &lt;dbl&gt; 89, 89, 89, 275, 274, 89, 365, 365, 365…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3, 0, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex1/Hands-onEx1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\n\nBuffering\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nSolution: Firstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex1/Hands-onEx1.html#point-in-polygon-count",
    "href": "Hands-on_Ex1/Hands-onEx1.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Point in Polygon count",
    "text": "Point in Polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to my site\nIn this website, im gonna share with you my learning journey.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Project/takehome_ex11.html",
    "href": "Project/takehome_ex11.html",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "pacman::p_load(tmap,sf,tidyverse,knitr,h3jsr,dplyr, mapview)"
  },
  {
    "objectID": "Project/takehome_ex11.html#getting-started",
    "href": "Project/takehome_ex11.html#getting-started",
    "title": "Take Home Exercise 1",
    "section": "",
    "text": "pacman::p_load(tmap,sf,tidyverse,knitr,h3jsr,dplyr, mapview)"
  },
  {
    "objectID": "Project/takehome_ex11.html#preparing-the-flow-data",
    "href": "Project/takehome_ex11.html#preparing-the-flow-data",
    "title": "Take Home Exercise 1",
    "section": "Preparing the Flow Data",
    "text": "Preparing the Flow Data\n\nImporting the OD data\nFirstly, we will import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall by using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202308.csv\")\n\nCheck odbus tibble data frame that values in OROGIN_PT_CODE and DESTINATION_PT_CODE are in numeric data type.\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nOrigin & Destination Bus Stop Code\n\nodbus$ORIGIN_PT_CODE &lt;-\nas.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;-\nas.factor(odbus$DESTINATION_PT_CODE)\n\n\n\nExtracting the Study Data\nFilter out data that belong to trips that occur on:\n\n“Weekday” and “6-9am” (wdmp)\n\nwdmp &lt;-  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekday” and “5-8pm” (wdap)\n\nwdap &lt;-  odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 &\n           TIME_PER_HOUR &lt;= 20) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekends/Holiday” and “11am-2pm” (hmp)\n\nhmp &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 &\n           TIME_PER_HOUR &lt;= 14) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n“Weekends/Holiday” and “4pm-7pm” (hep)\n\nhep &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKENDS/HOLIDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 &\n           TIME_PER_HOUR &lt;= 19) %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\nCheck resulting data tables\n\nkable(head(wdmp)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1973\n\n\n01013\n952\n\n\n01019\n1789\n\n\n01029\n2561\n\n\n01039\n2938\n\n\n01059\n1651\n\n\n\n\nkable(head(wdap)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n8448\n\n\n01013\n7328\n\n\n01019\n3608\n\n\n01029\n9317\n\n\n01039\n12937\n\n\n01059\n2133\n\n\n\n\nkable(head(hmp)) \n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n2273\n\n\n01013\n1697\n\n\n01019\n1511\n\n\n01029\n3272\n\n\n01039\n5424\n\n\n01059\n1062\n\n\n\n\nkable(head(hep))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n3208\n\n\n01013\n2796\n\n\n01019\n1623\n\n\n01029\n4244\n\n\n01039\n7403\n\n\n01059\n1190\n\n\n\n\n\nOutput saved in rds format for future use\n\nwrite_rds(wdmp, \"data/rds/wdmp.rds\") \nwrite_rds(wdap, \"data/rds/wdap.rds\") \nwrite_rds(hmp, \"data/rds/hmp.rds\") \nwrite_rds(hep, \"data/rds/hep.rds\")\n\nImport the rds file into R environment\n\nwdmp &lt;- read_rds(\"data/rds/wdmp.rds\") \nwdap &lt;- read_rds(\"data/rds/wdap.rds\") \nhmp &lt;- read_rds(\"data/rds/hmp.rds\") \nhep &lt;- read_rds(\"data/rds/hmp.rds\")"
  },
  {
    "objectID": "Project/takehome_ex11.html#working-with-geospatial-data",
    "href": "Project/takehome_ex11.html#working-with-geospatial-data",
    "title": "Take Home Exercise 1",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\nTwo geospatial data (shapefile) will be used for this exercise:\n\nBusStop: Provides location of bus stop as at Q4 2022\nMPSZ-2019: This data provides the sub-zone boundary of URA Master Plan 2019\n\n\nImporting geospatial data\n\nbusstop &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS624/Project/data/geospatial' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nCheck structure of busstop and MPSZ  sf tibble data frame\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…"
  },
  {
    "objectID": "Project/takehome_ex11.html#geospatial-data-wrangling",
    "href": "Project/takehome_ex11.html#geospatial-data-wrangling",
    "title": "Take Home Exercise 1",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nCombining Busstop & mpsz\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nSave output into rds format\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.csv\")"
  },
  {
    "objectID": "Project/takehome_ex11.html#setting-up-the-hexagon-grid",
    "href": "Project/takehome_ex11.html#setting-up-the-hexagon-grid",
    "title": "Take Home Exercise 1",
    "section": "Setting up the Hexagon Grid",
    "text": "Setting up the Hexagon Grid\n\nDrawing the Hexagon Grid\nDraw hexagon grid over the mpsz map\n\narea_honeycomb_grid = st_make_grid(mpsz, c(250, 250), what = \"polygons\", square = FALSE)\n\nConvert the hexagon grid to sf (simple features) object and add a new column grid_id (sequential identifier) to it\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\nDetermine which bus stops is contained within which hexagon using st_within.\n\nbusstop_honeycomb &lt;- st_intersection(honeycomb_grid_sf,busstop) %&gt;%\n  select(BUS_STOP_N, grid_id) %&gt;%\n  st_drop_geometry()\n\nSave output into rds format\n\nwrite_rds(busstop_honeycomb, \"data/rds/busstop_honeycomb.csv\")\n\nCheck for duplicate records\n\nduplicate &lt;- busstop_honeycomb %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nRetain unique records only\n\nbusstop_honeycomb &lt;- unique(busstop_honeycomb)\n\nOnly include hexagon grid IDs that have bus stop numbers\n\nbusstop_honeycomb &lt;- busstop_honeycomb %&gt;%\n  filter(!is.na(grid_id) & grid_id &gt; 0)\n\n\n\nAssign Each Bus Stop to a Grid ID\nFor all time periods, assign bus stops to a hexagon grid id. All NULL and 0 values are removed.\n\nwdmp_gridid &lt;- left_join(busstop_honeycomb, wdmp,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nwdmp_gridid &lt;- wdmp_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nwdap_gridid &lt;- left_join(busstop_honeycomb, wdap,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nwdap_gridid &lt;- wdap_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nhmp_gridid &lt;- left_join(busstop_honeycomb, hmp,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nhmp_gridid &lt;- hmp_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)\n\n\nhep_gridid &lt;- left_join(busstop_honeycomb, hep,\n            by = c(\"BUS_STOP_N\" = \"ORIGIN_PT_CODE\")) \n\nhep_gridid &lt;- hep_gridid %&gt;%\n  filter(!is.na(TRIPS) & TRIPS &gt; 0)"
  },
  {
    "objectID": "Project/takehome_ex11.html#choropleth-visualisation",
    "href": "Project/takehome_ex11.html#choropleth-visualisation",
    "title": "Take Home Exercise 1",
    "section": "Choropleth Visualisation",
    "text": "Choropleth Visualisation\nWeekday Morning Peak 6am-9am\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- wdmp_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb\n\n\n\n\n\n\n&lt;insert description of spatial patterns in 200 words&gt;\nWeekday Afternoon Peak 5pm-8pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- wdap_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Reds\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb\n\n\n\n\n\n\n&lt;insert description of spatial patterns in 200 words&gt;\nWeekend/Holiday Morning Peak 11am-2pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- hmp_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Greens\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb\n\n\n\n\n\n\n&lt;insert description of spatial patterns in 200 words&gt;\nCollate hexagon data for Weekend/Holiday Evening Peak 4pm-7pm\nSum up the trips per hexagon\n\ntotal_trips_by_grid &lt;- hep_gridid %&gt;%\n  group_by(grid_id) %&gt;%\n  summarise(total_trips = sum(TRIPS, na.rm = TRUE))\n\nMerge geospatial data\n\ntotal_trips_by_grid &lt;- total_trips_by_grid %&gt;%\n  left_join(honeycomb_grid_sf, by = c(\"grid_id\" = \"grid_id\"))\n\ntotal_trips_by_grid_sf &lt;- st_sf(total_trips_by_grid)\n\nPlot the Choropleth map\n\ntmap_mode(\"view\")\n\nmap_honeycomb = tm_shape(total_trips_by_grid_sf) +\n  tm_fill(\n    col = \"total_trips\",\n    palette = \"Greens\",\n    style = \"cont\",\n    title = \"Total Trips Taken - Weekday Morning Peak 6-9am\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.6,\n    popup.vars = c(\n      \"Number of trips: \" = \"total_trips\"\n    ),\n    popup.format = list(\n      total_trips = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.4)\n\nmap_honeycomb\n\n\n\n\n\n\n&lt;insert description of spatial patterns in 200 words&gt;"
  },
  {
    "objectID": "Project/takehome_ex11.html#local-indicators-of-spatial-association-lisa-analysis",
    "href": "Project/takehome_ex11.html#local-indicators-of-spatial-association-lisa-analysis",
    "title": "Take Home Exercise 1",
    "section": "Local Indicators of Spatial Association (LISA) Analysis",
    "text": "Local Indicators of Spatial Association (LISA) Analysis\n\nCompute LISA of the passengers trips generate by origin at hexagon level.\nDisplay the LISA maps of the passengers trips generate by origin at hexagon level. The maps should only display the significant (i.e. p-value &lt; 0.05)\nWith reference to the analysis results, draw statistical conclusions (not more than 200 words per visual)."
  },
  {
    "objectID": "Project/data/geospatial/MPSZ-2019.html",
    "href": "Project/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 1/data/geospatial/MPSZ-2019.html",
    "href": "In-class Exercise/In-class Exercise 1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-class Exercise/In-class Exercise 3/In_class_3.html",
    "href": "In-class Exercise/In-class Exercise 3/In_class_3.html",
    "title": "In-class_Ex3",
    "section": "",
    "text": "pacman::p_load(tmap, sf, sp, DT, stplanr,\n               performance, reshape2,\n               ggpubr, units, tidyverse)\n\n\nmpsz &lt;- read_rds(\"data/rds/mpsz.rds\")\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR"
  },
  {
    "objectID": "Hands-on_Ex1.html",
    "href": "Hands-on_Ex1.html",
    "title": "Handson Exercise 1",
    "section": "",
    "text": "This is the overview paragraph"
  },
  {
    "objectID": "Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex1.html#overview",
    "title": "Handson Exercise 1",
    "section": "",
    "text": "This is the overview paragraph"
  },
  {
    "objectID": "Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex1.html#getting-started",
    "title": "Handson Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex1.html#section",
    "href": "Hands-on_Ex1.html#section",
    "title": "Handson Exercise 1",
    "section": "",
    "text": "This is the getting started paragraph"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "to import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#objectives",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#objectives",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "to import and extract OD data for a selected time interval,\nto import and save geospatial data (i.e. bus stops and mpsz) into sf tibble data frame objects,\nto populate planning subzone code into bus stops sf tibble data frame,\nto construct desire lines geospatial data from the OD data, and\nto visualise passenger volume by origin and destination bus stops by using the desire lines data."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "title": "Hands-on_Ex3",
    "section": "Getting Started",
    "text": "Getting Started\n\nsf for importing, integrating, processing and transforming geospatial data.\ntidyverse for importing, integrating, wrangling and visualising data.\ntmap for creating thematic maps.\n\n\npacman::p_load(tmap, sf, DT, stplanr,\n               performance,\n               ggpubr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "title": "Hands-on_Ex3",
    "section": "Preparing the Flow Data",
    "text": "Preparing the Flow Data\n\nImporting the OD data\n\ngetwd()\n\n[1] \"/Users/youting/ytquek/ISSS624/Hands-on_Ex3\"\n\nodbus &lt;- read_csv(\"Data/aspatial/origin_destination_bus_202310.csv\")\n\nRows: 5694297 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE) \n\n\n\nExtracting the study data\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\n\ndatatable(odbus6_9)\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\n\n\nwrite_rds(odbus6_9, \"Data/rds/odbus6_9.rds\")\n\n\nodbus6_9 &lt;- read_rds(\"Data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "title": "Hands-on_Ex3",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\n\nImporting geospatial data\n\nbusstop &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex3/Data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"Data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `/Users/youting/ytquek/ISSS624/Hands-on_Ex3/Data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26..."
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "title": "Hands-on_Ex3",
    "section": "Geospatial data wrangling",
    "text": "Geospatial data wrangling\n\nCombining Busstop and mpsz\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\n\nwrite_rds(busstop_mpsz, \"Data/rds/busstop_mpsz.rds\")  \n\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(odbus6_9, busstop_mpsz, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 25632 of `x` matches multiple rows in `y`.\nℹ Row 673 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_data, busstop_mpsz, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 167 of `x` matches multiple rows in `y`.\nℹ Row 672 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\n\nwrite_rds(od_data, \"Data/rds/od_data.rds\")\n\n\nod_data &lt;- read_rds(\"Data/rds/od_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "href": "Hands-on_Ex3/Hands-on_Ex3.html#visualising-spatial-interaction",
    "title": "Hands-on_Ex3",
    "section": "Visualising Spatial Interaction",
    "text": "Visualising Spatial Interaction\n\nRemoving intra-zonal flows\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\n\nCreating desire lines\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\n\n\n\nVisualising the desire lines\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length"
  }
]