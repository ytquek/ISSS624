---
title: "Hands-on Exercise 4"
subtitle: "Geographically Weighted Models"
date: "5 Dec 2023"
date-modified: "last-modified"
format: html
editor: visual
---

## Overview

**Geographically weighted regression (GWR)** is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). 

In this hands-on exercise, a [hedonic pricing](https://www.investopedia.com/terms/h/hedonicpricing.asp) model will be built by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.

## **The Data**

Two data sets will be used in this model building exercise:

-   URA Master Plan subzone boundary in shapefile format (i.e. *MP14_SUBZONE_WEB_PL*)

-   condo_resale_2015 in csv format (i.e. *condo_resale_2015.csv*)

## **Getting Started**

R packages needed for this exercise are as follows:

-   R package for building OLS and performing diagnostics tests

    -   [**olsrr**](https://olsrr.rsquaredacademy.com/)

-   R package for calibrating geographical weighted family of models

    -   [**GWmodel**](https://cran.r-project.org/web/packages/GWmodel/)

-   R package for multivariate data visualisation and analysis

    -   [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)

-   Spatial data handling

    -   **sf**

-   Attribute data handling

    -   **tidyverse**, especially **readr**, **ggplot2** and **dplyr**

-   Choropleth mapping

    -   **tmap**

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

## **Geospatial Data Wrangling**

Import *MP_SUBZONE_WEB_PL* shapefile by using `st_read()` of **sf** packages.

### **Importing geospatial data**

```{r}
mpsz = st_read(dsn = "Data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

Note: The report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called *mpsz* and it is a simple feature object. The geometry type is *multipolygon*. it is also important to note that mpsz simple feature object does not have EPSG information.

### **Updating CRS information**

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

Verify the projection of the newly transformed *mpsz_svy21* by using `st_crs()` of **sf** package.

```{r}
st_crs(mpsz_svy21)
```

Note: EPSG is now indicated as *3414* 

```{r}
st_bbox(mpsz_svy21) #view extent
```

## **Aspatial Data Wrangling**

### ***Importing the aspatial data***

The *condo_resale_2015* is in csv file format. The codes chunk below uses `read_csv()` function of **readr** package to import *condo_resale_2015* into R as a tibble data frame called *condo_resale*.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```

Display *condo_resale* tibble data table

```{r}
glimpse(condo_resale)
```

See data in XCOORD column

```{r}
head(condo_resale$LONGITUDE)
```

See data in YCOORD column

```{r}
head(condo_resale$LATITUDE)
```

Summary Statistics

```{r}
summary(condo_resale)
```

### **Converting aspatial data frame into a sf object**

convert *condo_resale* tibble data frame into sf object

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

Display condo_resale content

```{r}
head(condo_resale.sf)
```

Note: Output is in point feature data frame.

## **Exploratory Data Analysis (EDA)**

### **EDA using statistical graphics**

Plot distribution of SELLING_PRICE

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

Note: The figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.

Statistically, the skewed dsitribution can be normalised by using log transformation.

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

Plot the *LOG_SELLING_PRICE*

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="blue")
```

Note: The distribution is relatively less skewed after the transformation.

### **Multiple Histogram Plots distribution of variables**

Draw multiple small histograms (aka trellis plot) by using `ggarrange()` of [**ggpubr**](https://cran.r-project.org/web/packages/ggpubr/) package.

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="salmon")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="salmon")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

### **Drawing Statistical Point Map**

Reveal the geospatial distribution condominium resale prices in Singapore

Note: [`tm_dots()`](https://www.rdocumentation.org/packages/tmap/versions/2.2/topics/tm_symbols) is used instead of `tm_bubbles()`.

`set.zoom.limits` argument of `tm_view()` sets the minimum and maximum zoom level to 11 and 14 respectively.

```{r}
tmap_mode("view")
tmap_options(check.and.fix = TRUE)

tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

Change tmap mode back to plot

```{r}
tmap_mode("plot")
```

## **Hedonic Pricing Modelling in R**

### **Simple Linear Regression Method**

Build a simple linear regression model, dependent variable: *SELLING_PRICE* , independent variable:  *AREA_SQM* 

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

Summary

```{r}
summary(condo.slr)
```

The output report reveals that the SELLING_PRICE can be explained by using the formula:

```         
      *y = -258121.1 + 14719x1*
```

R-squared = 0.4518 reveals that the simple regression model built is able to explain \~45% of the resale prices.

Since p-value\<0.05, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of *SELLING_PRICE*.

The **Coefficients:** section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.

### Visualise the best fit curve on a scatterplot

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

### **Multiple Linear Regression Method**

#### Visualising the relationships of the independent variables

Multicollinearity - Indepdent variables used are not highly correlated to each other, resulting in a compromised model performance

Correlation matrix is commonly used to visualise the relationships between the independent variables to prevent multicollinearity.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

Matrix reorder is very important for mining the hiden structure and pattern in the matrix. There are four methods in corrplot (parameter order), named "AOE" (used above), "FPC", "hclust", "alphabet".

From the scatterplot matrix, it is clear that ***Freehold*** is highly correlated to ***LEASE_99YEAR***. In view of this, it is wiser to only include either one of them in the subsequent model building. Thus, ***LEASE_99YEAR*** is excluded in the subsequent model building.

### **Building a hedonic pricing model using multiple linear regression method**

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

### **Preparing Publication Quality Table: olsrr method**

Revised the above model by removing variables which are statistically insignificant.

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### **Preparing Publication Quality Table: gtsummary method**

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

#### Checking for multicolinearity

```{r}
ols_vif_tol(condo.mlr1)
```

Note: Since the VIF of the independent variables are less than 10. It can be concluded that there are no sign of multicollinearity among the independent variables.

#### Test for Non-Linearity

In multiple linear regression, it is important to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

Note: The figure above reveals that most of the data points are scattered around the 0 line, thus it can be concluded that the relationships between the dependent variable and independent variables are linear.

#### Test for Normality Assumption

```{r}
ols_plot_resid_hist(condo.mlr1)
```

Note: The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.

#### Formal statistical test methods

```{r}
ols_test_normality(condo.mlr1)
```

Note: The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.

#### Testing for Spatial Autocorrelation

This hedonic model uses geographically referenced attributes, hence it is also important to visualise the residual of the hedonic pricing model.

Thus, to perform spatial autocorrelation test, we need to convert *condo_resale.sf* from sf data frame into a **SpatialPointsDataFrame**.

Export the residual of the hedonic pricing model and save it as a data frame

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Join the newly created data frame with *condo_resale.sf* object

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Convert *condo_resale.res.sf* from simple feature object into a SpatialPointsDataFrame

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

### Distribution of the residuals

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

Note: The figure above reveal that there is sign of spatial autocorrelation.

```{r}
tmap_mode("plot")
```

The Moran's I test will be performed to verify the observation

Compute the distance-based weight matrix 

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Convert the output neighbours lists (i.e. nb) into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

Moran's I test for residual spatial autocorrelation

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

The Global Moran's I test for residual spatial autocorrelation shows that it's p-value \< alpha value =0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.1424418 \>0, we can infer than the residuals resemble cluster distribution.

## **Building Hedonic Pricing Models using GWmodel**

### **Building Fixed Bandwidth GWR Model**

#### Computing fixed bandwith

Note: ***adaptive*** is set to **FALSE** , indicating computation of fixed bandwidth.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

::: {.callout-tip title="Statistical Conclusion" style="color: red"}
Output is in metre since the units used for [CRS 3414](https://epsg.io/3414) is meters.
:::

#### GWModel method - fixed bandwith

Calibrate the gwr model using fixed bandwidth and gaussian kernel.

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)
```

The output is saved in a list of class "gwrm".

Display the model output.

```{r}
gwr.fixed
```

The report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the global multiple linear regression model of 42967.1.

### **Building Adaptive Bandwidth GWR Model**

Calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.

#### Computing the adaptive bandwidth

Computation is similar to fixed bandwidth except the `adaptive` argument has changed to **TRUE**

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)
```

Note: Recommended data points = 30

#### Constructing the adaptive bandwidth gwr model

Calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel 

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)
```

Display the model output

```{r}
gwr.adaptive
```

Note: The report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61.

### **Visualising GWR Output**

### **Converting SDF into *sf* data.frame**

To visualise the fields in **SDF**, we need to first covert it into **sf** data.frame by using the code chunk below.

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)

condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  

gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

`glimpse()` is used to display the content of *condo_resale.sf.adaptive* sf data frame

```{r}
glimpse(condo_resale.sf.adaptive)
```

Summary

```{r}
summary(gwr.adaptive$SDF$yhat)
```

### **Visualising local R2**

Interactive point symbol map

```{r}
tmap_mode("view")

tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```

### **Visualising coefficient estimates**

```{r}
tmap_mode("view")
AREA_SQM_SE <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_SE",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

AREA_SQM_TV <- tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "AREA_SQM_TV",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))

tmap_arrange(AREA_SQM_SE, AREA_SQM_TV, 
             asp=1, ncol=2,
             sync = TRUE)
```

```{r}
tmap_mode("plot")
```

#### By URA Plannign Region

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)
```
